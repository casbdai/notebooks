{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The API key is provided on the LMS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "\n",
    "client = OpenAI(api_key=\"ENTER YOUR API KEY HERE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batched API Requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API requests are prone to error as they require a stable connection between client and server. A more efficient approach is to send all requests to the server at once and let the server decide how and when to handle them. This approach of bundling requests is called batching. OpenAI gives 50% discount on batched requests. However, as the process is asynchronus, you do not know when your batch will be ready. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>With French Socialists in Crisis, Manuel Valls...</td>\n",
       "      <td>BOISSEUIL, France  —   A furious   Ducourtioux...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All Donated Blood in U.S. Should Be Tested for...</td>\n",
       "      <td>The Food and Drug Administration on Friday too...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Eight Immigration Victories Won for Americans ...</td>\n",
       "      <td>Last year was a success for Americans who are ...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How To WATCH The Highly Anticipated ‘CLINTON C...</td>\n",
       "      <td>SHARE this link with everyone you know. EVERY ...</td>\n",
       "      <td>Real</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNBC: China’s Secret Plan to Crush the U.S. Sp...</td>\n",
       "      <td>In a feature on Tuesday, CNBC explained how th...</td>\n",
       "      <td>Fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  With French Socialists in Crisis, Manuel Valls...   \n",
       "1  All Donated Blood in U.S. Should Be Tested for...   \n",
       "2  Eight Immigration Victories Won for Americans ...   \n",
       "3  How To WATCH The Highly Anticipated ‘CLINTON C...   \n",
       "4  CNBC: China’s Secret Plan to Crush the U.S. Sp...   \n",
       "\n",
       "                                                text label  \n",
       "0  BOISSEUIL, France  —   A furious   Ducourtioux...  Fake  \n",
       "1  The Food and Drug Administration on Friday too...  Fake  \n",
       "2  Last year was a success for Americans who are ...  Fake  \n",
       "3  SHARE this link with everyone you know. EVERY ...  Real  \n",
       "4  In a feature on Tuesday, CNBC explained how th...  Fake  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "corpus = pd.read_csv(\"https://github.com/casbdai/notebooks/raw/main/Module2/Textmining/fake_news.csv\")\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Batch Request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define prompts and a function to create the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Score the likelihood that the text contains fakenews.\"\n",
    "system_addition = \" Score the text with a likelihood between 0 (very low) and 1 (very high).\\nReturn the score as JSON with the key 'score'. Make sure that only the JSON is returned.\"\n",
    "\n",
    "def create_batch_job(prompt: str, system_addition: str, df: pd.DataFrame, row_name=\"text\", temperature=0.1) -> str:\n",
    "  tasks = []\n",
    "\n",
    "  for index, row in df.iterrows():\n",
    "      description = row[row_name]\n",
    "      \n",
    "      task = {\n",
    "          \"custom_id\": f\"task-{index}\",\n",
    "          \"method\": \"POST\",\n",
    "          \"url\": \"/v1/chat/completions\",\n",
    "          \"body\": {\n",
    "              # This is what you would have in your Chat Completions API call\n",
    "              \"model\": \"gpt-3.5-turbo\",\n",
    "              \"temperature\": temperature,\n",
    "              \"response_format\": { \n",
    "                  \"type\": \"json_object\"\n",
    "              },\n",
    "              \"messages\": [\n",
    "                  {\n",
    "                      \"role\": \"system\",\n",
    "                      \"content\": prompt + system_addition\n",
    "                  },\n",
    "                  {\n",
    "                      \"role\": \"user\",\n",
    "                      \"content\": description[:400]\n",
    "                  }\n",
    "              ],\n",
    "          }\n",
    "      }\n",
    "      \n",
    "      tasks.append(task)\n",
    "\n",
    "  file_name = \"batch_tasks.jsonl\"\n",
    "\n",
    "  with open(file_name, 'w') as file:\n",
    "      for obj in tasks:\n",
    "          file.write(json.dumps(obj) + '\\n')\n",
    "\n",
    "  batch_file = client.files.create(\n",
    "    file=open(file_name, \"rb\"),\n",
    "    purpose=\"batch\"\n",
    "  )\n",
    "\n",
    "  batch_job = client.batches.create(\n",
    "    input_file_id=batch_file.id,\n",
    "    endpoint=\"/v1/chat/completions\",\n",
    "    completion_window=\"24h\"\n",
    "  )\n",
    "\n",
    "  return batch_job.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the function to create the batch request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job_id = create_batch_job(prompt, system_addition, corpus.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the status of your job by executing the following cell. If it is not ready yet wait a moment and run the cell again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_job = client.batches.retrieve(batch_job_id)\n",
    "print(batch_job)\n",
    "job_finished = batch_job.status == \"completed\"\n",
    "print(f\"Ready? {job_finished}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to retrieve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_results(result_file_id: str) -> pd.DataFrame:\n",
    "\n",
    "  result = client.files.content(result_file_id).content\n",
    "  result_file_name = \"batch_job_results.jsonl\"\n",
    "\n",
    "  with open(result_file_name, 'wb') as file:\n",
    "      file.write(result)\n",
    "\n",
    "  # Loading data from saved file\n",
    "  results = []\n",
    "  with open(result_file_name, 'r') as file:\n",
    "      for line in file:\n",
    "          # Parsing the JSON string into a dict and appending to the list of results\n",
    "          json_object = json.loads(line.strip())\n",
    "          results.append(json_object)\n",
    "\n",
    "  result_df = pd.DataFrame(columns=[\"score\"])\n",
    "\n",
    "  for res in results:\n",
    "      task_id = res['custom_id']\n",
    "      # Getting index from task id\n",
    "      index = task_id.split('-')[-1]\n",
    "      score = json.loads(res['response']['body']['choices'][0]['message']['content'])[\"score\"]\n",
    "      result_df.loc[index, \"score\"] = score\n",
    "\n",
    "  return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the function to get the results as a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_results(batch_job.output_file_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
