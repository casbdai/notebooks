{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx1euGvIDXK1",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Hands On - Fighting Foodwaste - Introduction to Forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9Vf8VnxEL-G",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8eQ13i_2Pdk",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "bakery = pd.read_csv(\"https://raw.githubusercontent.com/casbdai/datasets/main/bakery_sales.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZ_q2Lpe3ByL",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Check Structure of Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fb7lmlk5EN2M",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "bakery.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tATu7qlhKrfC",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "bakery.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXM0MBdqEXc5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Importing Data correctly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUwG9xvFmoOX",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Pandas has very good functionalities for dealing with time series - they save a tremendous lot of pre-processing work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvQr56qAF2KE",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "bakery = pd.read_csv(\"https://raw.githubusercontent.com/casbdai/datasets/main/bakery_sales.csv\", index_col=\"Date\", parse_dates=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMC8Xv7M2rhI",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "bakery.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEHFU-462xAW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "bakery.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKUmhCTiHXPN",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Exploring Time Series"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQURrdjOm-M-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Select A Product - Bread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzJRFqY4B272",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "bakery[\"quantity\"] = 1\n",
        "bakery.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvdLFWzo5TpY",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product = bakery[bakery[\"Item\"]==\"Bread\"]\n",
        "product.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cgLoI2DFa3s",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Resampling Time Series\n",
        "\n",
        "Pandas has extremely neat support for time series. The .resample() method easily allows to aggregate (upsample) and expand time series (downsample)\n",
        "\n",
        "- **D** daily level\n",
        "- **W** weekly level\n",
        "- **Q** daily level\n",
        "- **Y** daily level\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-cJ2_2p4xyY",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product.resample(\"D\").quantity.sum()  # daily"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxZXcmLsHedn",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product.resample(\"W\").quantity.sum()  # weeky"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPg8NiWUHke3",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product.resample(\"Q\").quantity.sum()  # quarterly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PCt2u_eIMCI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Plot Time Series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_tnpNZaIEWZ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product_ts = product.resample(\"D\").quantity.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOPgN49UIKsw",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product_ts.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AobptkTYI5tI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Create some Time Series Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8S10etgIfTu",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product_df = pd.DataFrame(product_ts)\n",
        "product_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex-2h9MSHDN-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Add \"day of the week\" feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8SfKPI0IpX5",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product_df[\"day_of_week\"] = product_df.index.weekday\n",
        "product_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiuyKoFTGO80",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "In pandas the week starts with 0 (Mondays) and ends with 6 (Sunday). Our data is going from Tuesday to Tuesday.\n",
        "\n",
        "We have data for 23 weeks and 1 day (in total 162 days). We drop the first day such that we have data on 23 full weeks (eases the handling of time series a bit)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqORhoAuG6Qw",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Dropping first instance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xy8uU3EpbK1D",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product_df = product_df.iloc[1: , :]\n",
        "product_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdVbYuluHNYd",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Add \"week of year\" Feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhNJf-cdHZ6P",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product_df.index.isocalendar().week"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbe76C87HWGw",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Due to the Wednesday to Tuesday structure of the data, we have inequally spaced weeks.\n",
        "\n",
        "But we can shift the weeks by two days such that we have \"effective weeks\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j68aqc-_IKpx",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product_df.loc[:, \"week_of_year\"] = product_df.index.shift(periods = - 2, freq = \"D\").isocalendar().week.values\n",
        "product_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEaoURE7IpZw",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "### Add \"is_closed\" feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WK2ZqzGgZ9pS",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "product_df.loc[:, \"is_closed\"] = (product_df[\"quantity\"]==0).astype(int)\n",
        "product_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtM71ciQJJc8",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Seasonal Decomposition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hu8hCyHu2OUN",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "a standarf plotting function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWZUIMtLTfCq",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "decomp = seasonal_decompose(product_df[\"quantity\"])\n",
        "decomp.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPXtLUEbWstJ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Create Test & Train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hzeQl3QhWyNK",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "test = product_df[-28:] # get last 28 days\n",
        "train = product_df[0:-28] # get data until first day of testing day"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k26ikAS5P7ow",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Naive Forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GYYrSNbQENn",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Import required modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06EegUvBQCBV",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import root_mean_squared_error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zB1BIDBZQNc6",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Make copy of training data \"history\" for walk forward validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vXmhir4jQV-k",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "history = train\n",
        "history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e9k5-jttQCio",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Initialize empty list for performance metrics in each week of the 4 weeks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_p_NEyZDQiJh",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "performance_collector = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wiTENqAHi0yl",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for w in test[\"week_of_year\"].unique():\n",
        "  y_pred = [history.tail(1)[\"quantity\"]]*7 # get value of last day of last week in history\n",
        "  actual = test[test[\"week_of_year\"]==w][\"quantity\"] # get actual values to be predicted in week w\n",
        "\n",
        "  history = pd.concat([history, test[test[\"week_of_year\"]==w]]) # append training data to history; we shift one week forward in next iteration\n",
        "  performance_collector.append(root_mean_squared_error(actual,y_pred)) #calculalate error in week w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIsZzLFOUPdm",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(performance_collector)\n",
        "print(np.mean(performance_collector))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7plmvFYsDlz",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "plot_week_NAIVE = pd.DataFrame({\"NAIVE\":performance_collector})\n",
        "plot_week_NAIVE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30gu-qY0UpCh",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def performance_week_plot(list_of_predictions):\n",
        "  import matplotlib.pyplot as plt\n",
        "  pd.concat(list_of_predictions, axis=1).plot(color=[\"#7FC97F\",\"#BEAED4\",\"#FDC086\",\"#FFFF99\"], alpha=0.5, linewidth=5)\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.xlabel(\"Week\")\n",
        "  plt.xticks(ticks=[0,1,2,3],labels=[\"1\",\"2\",\"3\",\"4\"])\n",
        "  plt.title(\"Performance by Week\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhdz_Y2-_p75",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "performance_week_plot([plot_week_NAIVE])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl7lM6THl21H",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "def performance_avg_plot(list_of_predictions):\n",
        "  import matplotlib.pyplot as plt\n",
        "  pd.concat(list_of_predictions, axis=1).mean().plot(kind=\"bar\",color=[\"#7FC97F\",\"#BEAED4\",\"#FDC086\",\"#FFFF99\"], alpha=0.6)\n",
        "  plt.ylabel(\"RMSE\")\n",
        "  plt.xlabel(\"Approach\")\n",
        "  plt.xticks(rotation=0)\n",
        "  plt.title(\"4 Weeks Average\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihi8BSDRC6PX",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "performance_avg_plot([plot_week_NAIVE])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKpjPHk7WBNj",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# SNAIVE Foreacasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfrDTg8hYPCZ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Initialize 4 Week-Forward Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHDlcYC-YQed",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "history = train\n",
        "performance_collector = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yM7XH4WYXk-",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 4 Week-Forward Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ui6jvaVoVak",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for w in test[\"week_of_year\"].unique():\n",
        "  y_pred = history.tail(7)[\"quantity\"]\n",
        "  actual = test[test[\"week_of_year\"]==w][\"quantity\"]\n",
        "\n",
        "  history = pd.concat([history, test[test[\"week_of_year\"]==w]])\n",
        "\n",
        "  performance_collector.append(root_mean_squared_error(actual,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56lz-PqqYaRg",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(performance_collector)\n",
        "print(np.mean(performance_collector))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VWlpDm04YhCs",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "plot_week_SNAIVE = pd.DataFrame({\"SNAIVE\":performance_collector})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lPIWO9RfWbnY",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "performance_week_plot([plot_week_NAIVE, plot_week_SNAIVE])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_rOHDhhlyRG",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "performance_avg_plot([plot_week_NAIVE, plot_week_SNAIVE])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYhs8nfmXRk5",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# ARIMA Forecasting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfNkw88gXVZ7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Plot ACF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIrnk8GGQ-Qt",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "acf = plot_acf(product_ts, lags=40,color='g')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWvVr3FKsgK7",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "*  Correlation of Time Series with lagged version of itself\n",
        "*  We see strong seasonal patterns: lags at day 7, 14, 21 are correlated with our sales >> there is a \"weekly sales memory\"\n",
        "*   To some extend also the day before\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l__fmHmXZPM",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Plot PACF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCe9wl05Sh1S",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "pacf = plot_pacf(product_ts, lags=40,color='g')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqN_OLKTtDmo",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "*  Pacf are somilar to acf, but pacf reduce the effect of prior lags\n",
        "*  Pacf can be used to decide how many lags to include\n",
        "*  We can see that the \"weekly sales memory\" becomes weaker over time, after week 3 (day 21) past sales does not contain no usable information any more\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uogsNmPkXe3x",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Initialize 4 Week-Forward Validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJmgnPfztsnF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "pmdarima is a very handy package for ARIMA, but it is not installed within the anaconda framework and google collab\n",
        "\n",
        "*   In Jupyter: the following command must be executed once\n",
        "*   In google collab: the following command must be executed everytime pmdarima should be used\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas==2.2.0\n",
        "!pip install pmdarima\n"
      ],
      "metadata": {
        "id": "2yvJdz4FLF-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0mO8z2LGXtKQ",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from pmdarima.arima import auto_arima\n",
        "history = train\n",
        "performance_collector = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybqq1YZjXxm8",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Train Auto ARIMA Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXy-JggWXva0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "arima = auto_arima(train[\"quantity\"], error_action='ignore', trace=True,\n",
        "                   suppress_warnings=True, maxiter=30,\n",
        "                   seasonal=True, m=7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Vl1wCjGX48r",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 4 Week-Forward Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYbAHqs-t8jc",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for w in test[\"week_of_year\"].unique():\n",
        "  y_pred = pd.Series(arima.predict(7))\n",
        "  actual = test[test[\"week_of_year\"]==w][\"quantity\"]\n",
        "\n",
        "  history = pd.concat([history, test[test[\"week_of_year\"]==w]])\n",
        "  arima.update(test[test[\"week_of_year\"]==w][\"quantity\"])\n",
        "\n",
        "  performance_collector.append(root_mean_squared_error(actual,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OtpuNnPPZcI6",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(performance_collector)\n",
        "print(np.mean(performance_collector))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyIAugcaZ016",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "plot_week_ARIMA = pd.DataFrame({\"ARIMA\":performance_collector})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTwCTC7BlRMb",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "performance_week_plot([plot_week_NAIVE, plot_week_SNAIVE,plot_week_ARIMA])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_br-d0zlr7S",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "performance_avg_plot([plot_week_NAIVE, plot_week_SNAIVE,plot_week_ARIMA])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM_EbJ3mZdX1",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Going Machine Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWK1xtwfaEbI",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Initial Feature Engineering\n",
        "\n",
        "Manually Define time lags. We have seen in the acf and pacf plots that going up to 2 weeks back in past might yield important information. So, we take day 7 to 14."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cPwY37u44Dl0",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "shifts = np.arange(7, 15).astype(int)\n",
        "shifts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UpOdAk-bagdJ",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "The following codes creates the shifted variables that we defined in **shifts**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVNc-f0DJhYV",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAHTb2815L3T",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "shifted_data = {\"lag_{}_day\".format(day_shift): train[\"quantity\"].shift(day_shift) for day_shift in shifts}\n",
        "shifted_data = pd.DataFrame(shifted_data)\n",
        "shifted_data.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_XamSleyazzg",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "We merge the shifted variables to our training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfBrF8QV5XAn",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "train = pd.concat([train,shifted_data],axis=1)\n",
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YykiZ2tHa45b",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Also we can use the seasonal component of the seasonal decomposition. We see that this patterns repeats all 7 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vGfPdvFbH4c",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "decomp.seasonal.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwiOjHOM54G9",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "train[\"seasonality\"] = decomp.seasonal\n",
        "train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UP5wbsfbd5P",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Delete NA from training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64ftWm5X6o7K",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "train = train.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpcBk3tpbk8L",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "Separate Feature and Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daAHKLvu8cMl",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "X_train = train.drop(\"quantity\", axis=1)\n",
        "y_train = train[\"quantity\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6V0r6c0bqoF",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Train Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5whQhcu64op",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "forecast_forest = RandomForestRegressor(n_estimators=10000)\n",
        "forecast_forest.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0OrQGxDb0A8",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## Initialze 4 Week-Forward Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "knOR0EY8b3vW",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "history = train\n",
        "performance_collector = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZWldHyacC1P",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "## 4 Week-Forward Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoEPHfqm6jnO",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "for w in test[\"week_of_year\"].unique():\n",
        "\n",
        "  dat = history.tail(14) # get last 14 days of available data\n",
        "\n",
        "  dat = pd.concat([dat,test[test[\"week_of_year\"]==w]]) #add test data\n",
        "\n",
        "  shifted_data = {\"lag_{}_day\".format(day_shift): dat[\"quantity\"].shift(day_shift) for day_shift in shifts} # lag training data\n",
        "  shifted_data = pd.DataFrame(shifted_data)\n",
        "\n",
        "  dat= pd.concat([dat[[\"quantity\",\"day_of_week\",\"week_of_year\",\"is_closed\"]],shifted_data],axis=1) # add shifted data\n",
        "\n",
        "  dat = dat.dropna() # delete missing data\n",
        "\n",
        "  dat[\"seasonality\"] = decomp.seasonal.head(7).values #add seasonal data\n",
        "  pred_dat = dat.drop(\"quantity\", axis=1)\n",
        "\n",
        "  y_pred = forecast_forest.predict(pred_dat)\n",
        "  actual = test[test[\"week_of_year\"]==w][\"quantity\"]\n",
        "\n",
        "  performance_collector.append(root_mean_squared_error(actual,y_pred))\n",
        "\n",
        "  history = pd.concat([history, dat])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "onVu0j5Rc1AV",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "print(performance_collector)\n",
        "print(np.mean(performance_collector))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPUeC_BafPxj",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "plot_week_RF = pd.DataFrame({\"RF\":performance_collector})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COb8DQohfWht",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "performance_week_plot([plot_week_NAIVE, plot_week_SNAIVE,plot_week_ARIMA,plot_week_RF])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kwc-gH0ugDls",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "performance_avg_plot([plot_week_NAIVE, plot_week_SNAIVE,plot_week_ARIMA,plot_week_RF])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "QQURrdjOm-M-",
        "2cgLoI2DFa3s",
        "7PCt2u_eIMCI",
        "AobptkTYI5tI",
        "ex-2h9MSHDN-",
        "vdVbYuluHNYd",
        "JEaoURE7IpZw",
        "wtM71ciQJJc8",
        "YfrDTg8hYPCZ",
        "1yM7XH4WYXk-",
        "wfNkw88gXVZ7",
        "8l__fmHmXZPM",
        "uogsNmPkXe3x",
        "Ybqq1YZjXxm8",
        "4Vl1wCjGX48r",
        "mWK1xtwfaEbI",
        "c6V0r6c0bqoF",
        "k0OrQGxDb0A8",
        "PZWldHyacC1P"
      ],
      "name": "Introduction to Forecasting COMPLETED.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 ('venv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "9cfc3c7994f631dfc6a65b56363e87144dd9fa5c38ebff28a3247fb8dab8888e"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}